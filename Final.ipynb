{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":150545,"sourceType":"datasetVersion","datasetId":70909}],"dockerImageVersionId":30587,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport cv2\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom sklearn.preprocessing import LabelEncoder\nimport numpy as np\nimport os\nimport mahotas\n\nimage_count = {}\ndefault_image_size = tuple((128, 128))  # Reduced image size\n\ndata = []\n\nfor root, _, files in os.walk('/kaggle/input/plantdisease/PlantVillage'):\n    disease = os.path.basename(root)\n    image_count[disease] = 0\n    \n    # Include images based on the starting word of the disease\n    if disease.lower().startswith(('pepper')):\n        print(disease)\n        for file in files:\n            if file.endswith('.jpg') or file.endswith('.png') or file.endswith('.JPG') or file.endswith('.PNG') or file.endswith('JPEG') or file.endswith('jpeg'):\n                image_path = os.path.join(root, file)\n\n                if image_count[disease] >= 1000:\n                    continue\n\n                # Read the original image and resize\n                original_image = cv2.imread(image_path)\n                original_image = cv2.resize(original_image, default_image_size)\n\n                # Perform Canny edge detection\n                gray_image = cv2.cvtColor(original_image, cv2.COLOR_BGR2GRAY)\n                edges = cv2.Canny(gray_image, 50, 150)\n\n                # Compute color histograms for each channel\n                hist_b = cv2.calcHist([original_image], [0], None, [256], [0, 256]).flatten().astype(int)\n                hist_g = cv2.calcHist([original_image], [1], None, [256], [0, 256]).flatten().astype(int)\n                hist_r = cv2.calcHist([original_image], [2], None, [256], [0, 256]).flatten().astype(int)\n\n                # Compute GLCM texture features\n                textures = mahotas.features.haralick(gray_image)\n                mean_texture = textures.mean(axis=0)\n\n                # Compute shape features using Hu Moments\n                moments = cv2.HuMoments(cv2.moments(gray_image)).flatten()\n\n                # Flatten the images and histograms to 1D arrays and convert to NumPy array\n                flattened_original_image = original_image.flatten().astype(int)\n                flattened_edges = edges.flatten().astype(int)\n                flattened_hist_b = hist_b.astype(int)\n                flattened_hist_g = hist_g.astype(int)\n                flattened_hist_r = hist_r.astype(int)\n                flattened_texture = mean_texture.astype(int)\n                flattened_moments = moments.astype(int)\n\n                # Concatenate the flattened pixel values, histograms, texture, moments, and disease name in data\n                combined_features = np.concatenate([flattened_original_image, flattened_edges, flattened_hist_b, flattened_hist_g, flattened_hist_r, flattened_texture, flattened_moments])\n                data.append([combined_features, disease])\n\n                # Increment the counter for the current disease\n                image_count[disease] += 1\n\n\ndf = pd.DataFrame(data, columns=['image_pixels', 'disease'])\n\n# Split the data into training and testing sets\nX = np.vstack(df['image_pixels'].to_numpy())\ny = df['disease']\n\n# Encode disease labels using LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train the model (using RandomForest as an example)\n# model = RandomForestClassifier(random_state=42)\nmodel = xgb.XGBClassifier()\nmodel.fit(X_train, y_train)\n\n# Make predictions on the test set\ny_pred = model.predict(X_test)\n\n# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-14T10:48:22.330136Z","iopub.execute_input":"2023-12-14T10:48:22.331438Z","iopub.status.idle":"2023-12-14T10:52:20.618215Z","shell.execute_reply.started":"2023-12-14T10:48:22.331396Z","shell.execute_reply":"2023-12-14T10:52:20.616908Z"},"trusted":true},"execution_count":189,"outputs":[{"name":"stdout","text":"Pepper__bell___Bacterial_spot\nPepper__bell___healthy\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype):\n/opt/conda/lib/python3.10/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n","output_type":"stream"},{"name":"stdout","text":"Accuracy: 0.94\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.94      0.95       207\n           1       0.94      0.95      0.94       193\n\n    accuracy                           0.94       400\n   macro avg       0.94      0.95      0.94       400\nweighted avg       0.95      0.94      0.95       400\n\nConfusion Matrix:\n [[195  12]\n [ 10 183]]\n","output_type":"stream"}]},{"cell_type":"code","source":"# model = RandomForestClassifier(n_estimators=100,random_state=42)\n# model.fit(X_train, y_train)\n\n# # Make predictions\n# y_pred = model.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.620345Z","iopub.execute_input":"2023-12-14T10:52:20.620644Z","iopub.status.idle":"2023-12-14T10:52:20.625175Z","shell.execute_reply.started":"2023-12-14T10:52:20.620618Z","shell.execute_reply":"2023-12-14T10:52:20.624014Z"},"trusted":true},"execution_count":190,"outputs":[]},{"cell_type":"code","source":"# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# # Define the parameter grid for Grid Search\n# param_grid = {\n#     'n_estimators': [50, 100, 200],\n#     'max_depth': [None, 10, 20],\n#     'min_samples_split': [2, 5, 10],\n#     'min_samples_leaf': [1, 2, 4]\n# }\n\n# # Create a RandomForestClassifier\n# rf = RandomForestClassifier(random_state=42)\n\n# # Initialize GridSearchCV\n# grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n\n# # Fit the grid search to the data\n# grid_search.fit(X_train, y_train)\n\n# # Print the best parameters found by Grid Search\n# print(\"Best Parameters:\", grid_search.best_params_)\n\n# # Get the best model\n# best_rf = grid_search.best_estimator_\n# y_pred = best_rf.predict(X_test)\n","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.626428Z","iopub.execute_input":"2023-12-14T10:52:20.626783Z","iopub.status.idle":"2023-12-14T10:52:20.634843Z","shell.execute_reply.started":"2023-12-14T10:52:20.626750Z","shell.execute_reply":"2023-12-14T10:52:20.633698Z"},"trusted":true},"execution_count":191,"outputs":[]},{"cell_type":"code","source":"# param_dist = {\n#     'max_depth': [3, 5, 7, 10, None],\n#     'learning_rate': [0.01, 0.1, 0.2, 0.3],\n#     'n_estimators': [50, 100, 200, 300],\n#     'subsample': [0.8, 0.9, 1.0],\n#     'colsample_bytree': [0.8, 0.9, 1.0],\n#     'gamma': [0, 1, 2],\n#     'min_child_weight': [1, 2, 3]\n# }\n\n# # Create an XGBClassifier\n# xgb_model = xgb.XGBClassifier(random_state=42)\n\n# # Initialize RandomizedSearchCV\n# random_search = RandomizedSearchCV(estimator=xgb_model, param_distributions=param_dist, n_iter=10, scoring='accuracy', cv=3, n_jobs=-1, random_state=42)\n\n# # Fit the random search to the data\n# random_search.fit(X_train, y_train)\n\n# # Print the best parameters found by RandomizedSearchCV\n# print(\"Best Parameters:\", random_search.best_params_)\n\n# # Get the best model\n# best_xgb = random_search.best_estimator_\n\n# # Make predictions on the test set\n# y_pred = best_xgb.predict(X_test)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.637325Z","iopub.execute_input":"2023-12-14T10:52:20.637715Z","iopub.status.idle":"2023-12-14T10:52:20.647901Z","shell.execute_reply.started":"2023-12-14T10:52:20.637677Z","shell.execute_reply":"2023-12-14T10:52:20.646735Z"},"trusted":true},"execution_count":192,"outputs":[]},{"cell_type":"code","source":"# import xgboost as xgb\n# # Now you can use XGBoost with the binary labels\n# model = xgb.XGBClassifier()\n# model.fit(X_train, y_train)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.649128Z","iopub.execute_input":"2023-12-14T10:52:20.649457Z","iopub.status.idle":"2023-12-14T10:52:20.658064Z","shell.execute_reply.started":"2023-12-14T10:52:20.649428Z","shell.execute_reply":"2023-12-14T10:52:20.656892Z"},"trusted":true},"execution_count":193,"outputs":[]},{"cell_type":"code","source":"# y_pred = model.predict(X_test)\n\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-14T10:52:20.659219Z","iopub.execute_input":"2023-12-14T10:52:20.659572Z","iopub.status.idle":"2023-12-14T10:52:20.668014Z","shell.execute_reply.started":"2023-12-14T10:52:20.659534Z","shell.execute_reply":"2023-12-14T10:52:20.666879Z"},"trusted":true},"execution_count":194,"outputs":[]},{"cell_type":"code","source":"len(X_train[0])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-14T10:52:20.669235Z","iopub.execute_input":"2023-12-14T10:52:20.669568Z","iopub.status.idle":"2023-12-14T10:52:20.680073Z","shell.execute_reply.started":"2023-12-14T10:52:20.669540Z","shell.execute_reply":"2023-12-14T10:52:20.678882Z"},"trusted":true},"execution_count":195,"outputs":[{"execution_count":195,"output_type":"execute_result","data":{"text/plain":"66324"},"metadata":{}}]},{"cell_type":"code","source":"print(image_count)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.681258Z","iopub.execute_input":"2023-12-14T10:52:20.681634Z","iopub.status.idle":"2023-12-14T10:52:20.688145Z","shell.execute_reply.started":"2023-12-14T10:52:20.681596Z","shell.execute_reply":"2023-12-14T10:52:20.686994Z"},"trusted":true},"execution_count":196,"outputs":[{"name":"stdout","text":"{'PlantVillage': 0, 'Pepper__bell___Bacterial_spot': 997, 'Potato___healthy': 0, 'Tomato_Leaf_Mold': 0, 'Tomato__Tomato_YellowLeaf__Curl_Virus': 0, 'Tomato_Bacterial_spot': 0, 'Tomato_Septoria_leaf_spot': 0, 'Tomato_healthy': 0, 'Tomato_Spider_mites_Two_spotted_spider_mite': 0, 'Tomato_Early_blight': 0, 'Tomato__Target_Spot': 0, 'Pepper__bell___healthy': 1000, 'Potato___Late_blight': 0, 'Tomato_Late_blight': 0, 'Potato___Early_blight': 0, 'Tomato__Tomato_mosaic_virus': 0}\n","output_type":"stream"}]},{"cell_type":"code","source":"accuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.689561Z","iopub.execute_input":"2023-12-14T10:52:20.689899Z","iopub.status.idle":"2023-12-14T10:52:20.697325Z","shell.execute_reply.started":"2023-12-14T10:52:20.689870Z","shell.execute_reply":"2023-12-14T10:52:20.696021Z"},"trusted":true},"execution_count":197,"outputs":[{"name":"stdout","text":"Accuracy: 0.945\n","output_type":"stream"}]},{"cell_type":"code","source":"f1 = f1_score(y_test, y_pred, average='weighted')\nf1","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-14T10:52:20.700594Z","iopub.execute_input":"2023-12-14T10:52:20.700900Z","iopub.status.idle":"2023-12-14T10:52:20.711639Z","shell.execute_reply.started":"2023-12-14T10:52:20.700873Z","shell.execute_reply":"2023-12-14T10:52:20.710518Z"},"trusted":true},"execution_count":198,"outputs":[{"execution_count":198,"output_type":"execute_result","data":{"text/plain":"0.9450082574316885"},"metadata":{}}]},{"cell_type":"code","source":"conf_matrix = confusion_matrix(y_test, y_pred)\nconf_matrix","metadata":{"tags":[],"execution":{"iopub.status.busy":"2023-12-14T10:52:20.712744Z","iopub.execute_input":"2023-12-14T10:52:20.713101Z","iopub.status.idle":"2023-12-14T10:52:20.720921Z","shell.execute_reply.started":"2023-12-14T10:52:20.713058Z","shell.execute_reply":"2023-12-14T10:52:20.719914Z"},"trusted":true},"execution_count":199,"outputs":[{"execution_count":199,"output_type":"execute_result","data":{"text/plain":"array([[195,  12],\n       [ 10, 183]])"},"metadata":{}}]},{"cell_type":"code","source":"# Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy:.2f}\")\n\n# Print classification report\nprint(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n\n# Print confusion matrix\nprint(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))","metadata":{"execution":{"iopub.status.busy":"2023-12-14T10:52:20.722282Z","iopub.execute_input":"2023-12-14T10:52:20.722616Z","iopub.status.idle":"2023-12-14T10:52:20.741258Z","shell.execute_reply.started":"2023-12-14T10:52:20.722588Z","shell.execute_reply":"2023-12-14T10:52:20.740307Z"},"trusted":true},"execution_count":200,"outputs":[{"name":"stdout","text":"Accuracy: 0.94\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.95      0.94      0.95       207\n           1       0.94      0.95      0.94       193\n\n    accuracy                           0.94       400\n   macro avg       0.94      0.95      0.94       400\nweighted avg       0.95      0.94      0.95       400\n\nConfusion Matrix:\n [[195  12]\n [ 10 183]]\n","output_type":"stream"}]}]}